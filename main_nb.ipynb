{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import psycopg2\n",
    "from collections import deque\n",
    "\n",
    "TIKI_URL = 'https://tiki.vn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(url):\n",
    "    try:\n",
    "        response = requests.get(url).text\n",
    "        response = BeautifulSoup(response, \"html.parser\")\n",
    "        return response\n",
    "    except Exception as err:\n",
    "        print(f'ERROR: {err}')\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATEGORIES SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(user=\"nhanpham\", database=\"tikifinal\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "def create_category_table():\n",
    "    query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS categories(\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                name VARCHAR(255),\n",
    "                url TEXT,\n",
    "                parent_id INT,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\"\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as err:\n",
    "        print(f'ERROR: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    def __init__(self, cat_id, name, url, parent_id):\n",
    "        self.cat_id = cat_id\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.parent_id = parent_id\n",
    "        \n",
    "    def save_into_db(self):\n",
    "        query = f'SELECT url FROM categories WHERE url LIKE %s;'\n",
    "        val = self.url\n",
    "        try:\n",
    "            cur.execute(query, val)\n",
    "            result = cur.fetchall()\n",
    "            if len(result) > 0:\n",
    "                return ''\n",
    "        except Exception as err:\n",
    "            print(f'ERROR: {err}')\n",
    "            \n",
    "        query = f\"\"\"\n",
    "                INSERT INTO categories (name, url, parent_id) \n",
    "                VALUES (%s, %s, %s) RETURNING id;\n",
    "                \"\"\"\n",
    "        val = (self.name, self.url, self.parent_id)\n",
    "        try:\n",
    "            cur.execute(query, val)\n",
    "            #GET ID FROM NEW ROW \n",
    "            self.cat_id = cur.fetchone()[0]\n",
    "        except Exception as err:\n",
    "            print(f'ERROR: {err}')\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'ID: {self.cat_id}, Name: {self.name}, URL: {self.url}, Parent ID: {self.parent_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_categories(save_db=False):\n",
    "    s = parse(TIKI_URL)\n",
    "    category_list = []\n",
    "    for i in s.findAll('a',{'class':'MenuItem__MenuLink-tii3xq-1 efuIbv'}):\n",
    "        cat_id = None\n",
    "        name = i.find('span', {'class':'text'}).text \n",
    "        url = i['href'] + \"&page=1\"\n",
    "        parent_id = None\n",
    "        cat = Category(None, name, url, parent_id)\n",
    "        if save_db:\n",
    "            cat.save_into_db()\n",
    "        category_list.append(cat)\n",
    "        \n",
    "    return category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_categories(category, save_db=False):\n",
    "    name = category.name\n",
    "    url = category.url\n",
    "    sub_categories = []\n",
    "\n",
    "    try:\n",
    "        div_containers = parse(url).find_all('div', attrs={\"class\": \"list-group-item is-child\"})\n",
    "        for div in div_containers:\n",
    "            sub_id = None\n",
    "            sub_name = ' '.join(div.a.text.split()[:-1])\n",
    "            sub_url = 'https://tiki.vn' + div.a.get('href')\n",
    "            sub_parent_id = category.cat_id\n",
    "            \n",
    "            cat = Category(sub_id, sub_name, sub_url, sub_parent_id)\n",
    "            if save_db:\n",
    "                cat.save_into_db()\n",
    "            if cat.cat_id is not None:\n",
    "                sub_categories.append(cat)\n",
    "    except Exception as err:\n",
    "        print(f'ERROR: {err}')\n",
    "    \n",
    "    return sub_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_categories(main_categories):\n",
    "    queue = deque(main_categories)\n",
    "    count = 0\n",
    "    \n",
    "    while queue:\n",
    "        parent_cat = queue.popleft()\n",
    "        sub_list = get_sub_categories(parent_cat, save_db=True)\n",
    "        queue.extend(sub_list)\n",
    "        \n",
    "        # sub_list is empty, which mean the parent_cat has no sub-categories\n",
    "        if not sub_list:\n",
    "            count+=1\n",
    "            if count % 100 == 0:\n",
    "                print(f'{count} number of deepest nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 number of deepest nodes\n",
      "200 number of deepest nodes\n",
      "300 number of deepest nodes\n",
      "400 number of deepest nodes\n",
      "500 number of deepest nodes\n",
      "600 number of deepest nodes\n",
      "700 number of deepest nodes\n",
      "800 number of deepest nodes\n",
      "900 number of deepest nodes\n",
      "1000 number of deepest nodes\n",
      "1100 number of deepest nodes\n",
      "1200 number of deepest nodes\n",
      "1300 number of deepest nodes\n",
      "1400 number of deepest nodes\n",
      "1500 number of deepest nodes\n",
      "1600 number of deepest nodes\n",
      "1700 number of deepest nodes\n",
      "1800 number of deepest nodes\n",
      "1900 number of deepest nodes\n",
      "2000 number of deepest nodes\n",
      "2100 number of deepest nodes\n",
      "2200 number of deepest nodes\n",
      "2300 number of deepest nodes\n",
      "2400 number of deepest nodes\n",
      "2500 number of deepest nodes\n",
      "2600 number of deepest nodes\n",
      "CPU times: user 16min 36s, sys: 9.69 s, total: 16min 45s\n",
      "Wall time: 1h 6min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "create_category_table()\n",
    "main_categories = get_main_categories(save_db=True)\n",
    "get_all_categories(main_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCT SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_product_table():\n",
    "    query = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS products(id SERIAL PRIMARY KEY,\n",
    "                                                data_id INT,\n",
    "                                                seller_id INT,\n",
    "                                                name VARCHAR(255),\n",
    "                                                price INT,\n",
    "                                                img TEXT,\n",
    "                                                cat_id INT,\n",
    "                                                submaster_cat VARCHAR(255),\n",
    "                                                submaster_link TEXT,\n",
    "                                                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                                                );\n",
    "            \"\"\"\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "    except Exception as err:\n",
    "        print(f'ERROR: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product:\n",
    "    def __init__(self, product_id, data_id, seller_id, name, price, img, cat_id, submaster_cat, submaster_link):\n",
    "        self.product_id = product_id\n",
    "        self.data_id = data_id \n",
    "        self.seller_id = seller_id\n",
    "        self.name = name\n",
    "        self.price = price\n",
    "        self.img = img \n",
    "        self.cat_id = cat_id\n",
    "        self.submaster_cat = submaster_cat\n",
    "        self.submaster_link = submaster_link\n",
    "        \n",
    "    def save_into_db(self):\n",
    "        query = f\"\"\"\n",
    "                INSERT INTO products (data_id, seller_id, name, price, img, cat_id, submaster_cat, submaster_link) \n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s) RETURNING id;\n",
    "                \"\"\"\n",
    "        val = (self.data_id, self.seller_id, self.name, self.price, self.img, self.cat_id, self.submaster_cat, self.submaster_link)\n",
    "        try:\n",
    "            cur.execute(query, val)\n",
    "        except Exception as err:\n",
    "            print(f'ERROR: {err}')\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'ID: {self.product_id}, Data ID: {self.data_id}, Seller ID: {self.seller_id}, Name: {self.name}, Price: {self.price}, IMG: {self.img}, Category ID: {self.cat_id}, Sub Master Category: {self.submaster_cat}, Sub Master Link: {self.submaster_link}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_one(cat, sub_url):\n",
    "    \"\"\" return scraped products in one page of certain category\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    s = parse(sub_url)\n",
    "    product_items = s.findAll('div',{'class':'product-item'})\n",
    "    if len(product_items) == 0:\n",
    "        return []\n",
    "    else: \n",
    "        for i in range(len(product_items)):\n",
    "            row = [product_items[i]['data-id'], \n",
    "                   product_items[i]['data-seller-product-id'] if len(product_items[i]['data-seller-product-id']) != 0 else None, \n",
    "                   product_items[i]['data-title'],\n",
    "                   product_items[i]['data-price'], \n",
    "                   product_items[i].find('img',{'class':'product-image img-responsive'})['src'], \n",
    "                   cat,\n",
    "                   s.find('div',{'class':'breadcrumb-wrap'}).find('ul').findAll('li')[2].text,\n",
    "                   'https://tiki.vn' + s.find('div',{'class':'breadcrumb-wrap'}).find('ul').findAll('li')[2].a.get('href') +'?src=tree'\n",
    "                   ]\n",
    "            results.append(row)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nochild_cate():\n",
    "    \"\"\" return all the categories that have no sub categories\n",
    "    \"\"\"\n",
    "    query = (\"\"\"SELECT p.url, p.id \n",
    "                FROM categories as p \n",
    "                LEFT JOIN categories as c ON c.parent_id = p.id \n",
    "                WHERE c.id IS NULL;\n",
    "                \"\"\")\n",
    "    cur.execute(query)\n",
    "    sub_cate_list = cur.fetchall()\n",
    "\n",
    "    for sub_cate in sub_cate_list:\n",
    "        temp = list(sub_cate)\n",
    "        temp[0] += '&page=1'\n",
    "        sub_cate_list[sub_cate_list.index(sub_cate)] = tuple(temp) \n",
    "    \n",
    "    return sub_cate_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://tiki.vn/bong-tam-cho-be/c10460?src=tree&page=1', 2848),\n",
       " ('https://tiki.vn/usb-luu-tru/c1828?src=tree&page=1', 251),\n",
       " ('https://tiki.vn/tinh-chat-duong-am/c11695?src=tree&page=1', 2026),\n",
       " ('https://tiki.vn/presentation/c76?src=tree&page=1', 3028),\n",
       " ('https://tiki.vn/business-economics/c21306?src=tree&page=1', 2409),\n",
       " ('https://tiki.vn/sua-duong-am/c11691?src=tree&page=1', 2024),\n",
       " ('https://tiki.vn/modem-adsl/c4585?src=tree&page=1', 264),\n",
       " ('https://tiki.vn/luoc-cho-be/c10459?src=tree&page=1', 2847),\n",
       " ('https://tiki.vn/o-cung-hdd/c4051?src=tree&page=1', 1350),\n",
       " ('https://tiki.vn/thiet-bi-so-khac/c21440?src=tree&page=1', 1070)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_cate_list = get_nochild_cate()\n",
    "sub_cate_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all(page_limit=10, product_limit=100000):\n",
    "    \"\"\" return scrape products from all the last-level categories\n",
    "        (categories without children)\n",
    "    \"\"\"\n",
    "    \n",
    "    print('INFO scrape_all(): Start scraping')\n",
    "\n",
    "    queue = sub_cate_list \n",
    "    while queue:\n",
    "        url = queue[0][0]\n",
    "        cat = queue[0][1]\n",
    "        queue = queue[1:]\n",
    "        \n",
    "        results = []\n",
    "        new_rows = scrape_one(cat, url)\n",
    "        if new_rows:\n",
    "            for product in new_rows:\n",
    "                id_ = None \n",
    "                data_id = product[0]\n",
    "                seller_id = product[1]\n",
    "                name = product[2]\n",
    "                price = product[3]\n",
    "                img = product[4]\n",
    "                cat_id = product[5]\n",
    "                sub_master_cat = product[6]\n",
    "                sub_master_link = product[7]\n",
    "\n",
    "                product = Product(id_, data_id, seller_id, name, price, img, cat_id, sub_master_cat, sub_master_link)\n",
    "                product.save_into_db()\n",
    "                results += new_rows \n",
    "        \n",
    "        # Generate next page url \n",
    "            page = int(url[-1]) + 1\n",
    "            url = url[:-1] + str(page)\n",
    "            \n",
    "        # Checking limit\n",
    "            if page < page_limit:\n",
    "                queue.append((url,cat))\n",
    "            query = 'SELECT COUNT(*) FROM products'\n",
    "            cur.execute(query) \n",
    "            \n",
    "            if cur.fetchall()[0][0] > product_limit:\n",
    "                print('Task completed!')\n",
    "                return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_product_table()\n",
    "scrape_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
